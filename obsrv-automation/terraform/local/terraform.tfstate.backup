{
  "version": 4,
  "terraform_version": "1.3.5",
  "serial": 5,
  "lineage": "40e2de95-17ec-91c0-5fd5-455d3af0f640",
  "outputs": {},
  "resources": [
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "kafka",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "../../helm_charts/kafka",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": true,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "kafka",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "2.8.0",
                "chart": "kafka",
                "name": "kafka",
                "namespace": "kafka",
                "revision": 1,
                "values": "{\"advertisedListeners\":[],\"affinity\":{},\"allowEveryoneIfNoAclFound\":true,\"allowPlaintextListener\":true,\"args\":[],\"auth\":{\"clientProtocol\":\"plaintext\",\"interBrokerProtocol\":\"plaintext\",\"jaas\":{\"clientPasswords\":[],\"clientUsers\":[\"user\"],\"existingSecret\":\"\",\"interBrokerPassword\":\"\",\"interBrokerUser\":\"admin\",\"zookeeperPassword\":\"\",\"zookeeperUser\":\"\"},\"jksKeystoreSAN\":\"\",\"jksPassword\":\"\",\"jksSecret\":\"\",\"jksTruststore\":\"\",\"jksTruststoreSecret\":\"\",\"sasl\":{\"interBrokerMechanism\":\"plain\",\"jaas\":{\"clientPasswords\":[],\"clientUsers\":[\"user\"],\"existingSecret\":\"\",\"interBrokerPassword\":\"\",\"interBrokerUser\":\"admin\",\"zookeeperPassword\":\"\",\"zookeeperUser\":\"\"},\"mechanisms\":\"plain,scram-sha-256,scram-sha-512\"},\"saslInterBrokerMechanism\":\"plain\",\"saslMechanisms\":\"plain,scram-sha-256,scram-sha-512\",\"tls\":{\"autoGenerated\":false,\"endpointIdentificationAlgorithm\":\"https\",\"existingSecret\":\"\",\"existingSecrets\":[],\"jksKeystoreSAN\":\"\",\"jksTruststore\":\"\",\"jksTruststoreSecret\":\"\",\"password\":\"\",\"type\":\"jks\"},\"tlsEndpointIdentificationAlgorithm\":\"https\"},\"authorizerClassName\":\"\",\"autoCreateTopicsEnable\":true,\"clusterDomain\":\"cluster.local\",\"command\":[\"/scripts/setup.sh\"],\"commonAnnotations\":{},\"commonLabels\":{},\"config\":\"\",\"containerSecurityContext\":{},\"customLivenessProbe\":{},\"customReadinessProbe\":{},\"defaultReplicationFactor\":1,\"deleteTopicEnable\":true,\"diagnosticMode\":{\"args\":[\"infinity\"],\"command\":[\"sleep\"],\"enabled\":false},\"existingConfigmap\":\"\",\"existingLog4jConfigMap\":\"\",\"externalAccess\":{\"autoDiscovery\":{\"enabled\":true,\"image\":{\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/kubectl\",\"tag\":\"1.19.15-debian-10-r39\"},\"resources\":{\"limits\":{},\"requests\":{}}},\"enabled\":true,\"service\":{\"annotations\":{},\"domain\":\"\",\"loadBalancerIPs\":[],\"loadBalancerSourceRanges\":[],\"nodePorts\":[],\"port\":\"9092\",\"type\":\"NodePort\",\"useHostIPs\":false,\"usePodIPs\":false}},\"externalZookeeper\":{\"servers\":[]},\"extraDeploy\":[],\"extraEnvVars\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"fullnameOverride\":\"\",\"global\":{\"imagePullSecrets\":[],\"imageRegistry\":\"\",\"storageClass\":\"\"},\"heapOpts\":\"-Xmx1024m -Xms1024m\",\"hostAliases\":[],\"image\":{\"debug\":false,\"pullPolicy\":\"Always\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/kafka\",\"tag\":\"2.8.1-debian-10-r31\"},\"initContainers\":[],\"interBrokerListenerName\":\"INTERNAL\",\"listenerSecurityProtocolMap\":\"\",\"listeners\":[],\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":5},\"log4j\":\"\",\"logFlushIntervalMessages\":\"_10000\",\"logFlushIntervalMs\":1000,\"logPersistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"annotations\":{},\"enabled\":false,\"existingClaim\":\"\",\"existingLogClaim\":\"\",\"mountPath\":\"/opt/bitnami/kafka/logs\",\"selector\":{},\"size\":\"8Gi\"},\"logRetentionBytes\":\"_1073741824\",\"logRetentionCheckIntervalMs\":300000,\"logRetentionHours\":168,\"logSegmentBytes\":\"_1073741824\",\"logsDirs\":\"/bitnami/kafka/data\",\"maxMessageBytes\":\"_1000012\",\"metrics\":{\"jmx\":{\"config\":\"jmxUrl: service:jmx:rmi:///jndi/rmi://127.0.0.1:5555/jmxrmi\\nlowercaseOutputName: true\\nlowercaseOutputLabelNames: true\\nssl: false\\nwhitelistObjectNames: [\\\"\\\\\\\"kafka.controller:*\\\\\\\", \\\\\\\"kafka.server:*\\\\\\\", \\\\\\\"java.lang:*\\\\\\\", \\\\\\\"kafka.network:*\\\\\\\", \\\\\\\"kafka.log:*\\\\\\\"\\\"]\",\"enabled\":false,\"existingConfigmap\":\"\",\"image\":{\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/jmx-exporter\",\"tag\":\"0.16.1-debian-10-r103\"},\"resources\":{\"limits\":{},\"requests\":{}},\"service\":{\"annotations\":{\"prometheus.io/path\":\"/\",\"prometheus.io/port\":\"5556\",\"prometheus.io/scrape\":\"true\"},\"clusterIP\":\"\",\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePort\":\"\",\"port\":5556,\"type\":\"ClusterIP\"},\"whitelistObjectNames\":[\"kafka.controller:*\",\"kafka.server:*\",\"java.lang:*\",\"kafka.network:*\",\"kafka.log:*\"]},\"kafka\":{\"affinity\":{},\"certificatesSecret\":\"\",\"enabled\":false,\"extraFlags\":{},\"image\":{\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/kafka-exporter\",\"tag\":\"1.4.2-debian-10-r41\"},\"initContainers\":[],\"nodeSelector\":{},\"podAnnotations\":{},\"podLabels\":{},\"resources\":{\"limits\":{},\"requests\":{}},\"schedulerName\":\"\",\"service\":{\"annotations\":{\"prometheus.io/path\":\"/metrics\",\"prometheus.io/port\":\"9308\",\"prometheus.io/scrape\":\"true\"},\"clusterIP\":\"\",\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePort\":\"\",\"port\":9308,\"type\":\"ClusterIP\"},\"serviceAccount\":{\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"\"},\"tlsCaCert\":\"ca-file\",\"tlsCaSecret\":\"\",\"tlsCert\":\"cert-file\",\"tlsKey\":\"key-file\",\"tolerations\":[]},\"serviceMonitor\":{\"enabled\":false,\"interval\":\"\",\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scrapeTimeout\":\"\",\"selector\":{}}},\"minBrokerId\":0,\"nameOverride\":\"\",\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{},\"numIoThreads\":8,\"numNetworkThreads\":3,\"numPartitions\":1,\"numRecoveryThreadsPerDataDir\":1,\"offsetsTopicReplicationFactor\":1,\"pdb\":{\"create\":false,\"maxUnavailable\":1,\"minAvailable\":\"\"},\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"annotations\":{},\"enabled\":true,\"existingClaim\":\"\",\"mountPath\":\"/bitnami/kafka\",\"selector\":{},\"size\":\"2Gi\",\"storageClass\":\"\"},\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podManagementPolicy\":\"Parallel\",\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001,\"runAsUser\":1001},\"priorityClassName\":\"\",\"provisioning\":{\"args\":[],\"command\":[],\"enabled\":false,\"numPartitions\":1,\"podAnnotations\":{},\"replicationFactor\":1,\"resources\":{\"limits\":{},\"requests\":{}},\"schedulerName\":\"\",\"topics\":[]},\"rbac\":{\"create\":true},\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":6,\"initialDelaySeconds\":5,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":5},\"replicaCount\":\"1\",\"resources\":{\"limits\":{},\"requests\":{}},\"rollingUpdatePartition\":\"\",\"schedulerName\":\"\",\"service\":{\"annotations\":{},\"externalPort\":9094,\"internalPort\":9093,\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePorts\":{\"client\":\"\",\"external\":\"\"},\"port\":9092,\"type\":\"ClusterIP\"},\"serviceAccount\":{\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"\"},\"sidecars\":[],\"socketReceiveBufferBytes\":102400,\"socketRequestMaxBytes\":\"_104857600\",\"socketSendBufferBytes\":102400,\"superUsers\":\"User:admin\",\"terminationGracePeriodSeconds\":\"\",\"tolerations\":[],\"topologySpreadConstraints\":{},\"transactionStateLogMinIsr\":1,\"transactionStateLogReplicationFactor\":1,\"updateStrategy\":\"RollingUpdate\",\"volumePermissions\":{\"enabled\":false,\"image\":{\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/bitnami-shell\",\"tag\":\"10-debian-10-r234\"},\"resources\":{\"limits\":{},\"requests\":{}},\"securityContext\":{\"runAsUser\":0}},\"zookeeper\":{\"auth\":{\"clientPassword\":\"\",\"clientUser\":\"\",\"enabled\":false,\"serverPasswords\":\"\",\"serverUsers\":\"\"},\"enabled\":\"true\",\"heapSize\":\"256\",\"replicaCount\":\"1\"},\"zookeeperConnectionTimeoutMs\":6000}",
                "version": "14.0.0"
              }
            ],
            "name": "kafka",
            "namespace": "kafka",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": null,
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "## @section Global parameters\n## Global Docker image parameters\n## Please, note that this will override the image parameters, including dependencies, configured to use the global value\n## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass\n\n## @param global.imageRegistry Global Docker image registry\n## @param global.imagePullSecrets Global Docker registry secret names as an array\n## @param global.storageClass Global StorageClass for Persistent Volume(s)\n##\nglobal:\n  imageRegistry: \"\"\n  ## E.g.\n  ## imagePullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  imagePullSecrets: []\n  storageClass: \"\"\n\n## @section Common parameters\n\n## @param nameOverride String to partially override kafka.fullname\n##\nnameOverride: \"\"\n## @param fullnameOverride String to fully override kafka.fullname\n##\nfullnameOverride: \"\"\n## @param clusterDomain Default Kubernetes cluster domain\n##\nclusterDomain: cluster.local\n## @param commonLabels Labels to add to all deployed objects\n##\ncommonLabels: {}\n## @param commonAnnotations Annotations to add to all deployed objects\n##\ncommonAnnotations: {}\n## @param extraDeploy Array of extra objects to deploy with the release\n##\nextraDeploy: []\n\n## Enable diagnostic mode in the deployment\n##\ndiagnosticMode:\n  ## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)\n  ##\n  enabled: false\n  ## @param diagnosticMode.command Command to override all containers in the deployment\n  ##\n  command:\n    - sleep\n  ## @param diagnosticMode.args Args to override all containers in the deployment\n  ##\n  args:\n    - infinity\n\n## @section Kafka parameters\n\n## Bitnami Kafka image version\n## ref: https://hub.docker.com/r/bitnami/kafka/tags/\n## @param image.registry Kafka image registry\n## @param image.repository Kafka image repository\n## @param image.tag Kafka image tag (immutable tags are recommended)\n## @param image.pullPolicy Kafka image pull policy\n## @param image.pullSecrets Specify docker-registry secret names as an array\n## @param image.debug Set to true if you would like to see extra information on logs\n##\nimage:\n  registry: docker.io\n  repository: \"bitnami/kafka\"\n  tag: \"2.8.1-debian-10-r31\"\n  ## Specify a imagePullPolicy\n  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n  ##\n  pullPolicy: Always\n  ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ## Example:\n  ## pullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  pullSecrets: []\n  ## Set to true if you would like to see extra information on logs\n  ##\n  debug: false\n## @param config Configuration file for Kafka. Auto-generated based on other parameters when not specified (see [below](\n## Specify content for server.properties\n## NOTE: This will override any KAFKA_CFG_ environment variables (including those set by the chart)\n## The server.properties is auto-generated based on other parameters when this parameter is not specified\n##\n## Example:\n## config: |-\n##   broker.id=-1\n##   listeners=PLAINTEXT://:9092\n##   advertised.listeners=PLAINTEXT://KAFKA_IP:9092\n##   num.network.threads=3\n##   num.io.threads=8\n##   socket.send.buffer.bytes=102400\n##   socket.receive.buffer.bytes=102400\n##   socket.request.max.bytes=104857600\n##   log.dirs=/bitnami/kafka/data\n##   num.partitions=1\n##   num.recovery.threads.per.data.dir=1\n##   offsets.topic.replication.factor=1\n##   transaction.state.log.replication.factor=1\n##   transaction.state.log.min.isr=1\n##   log.flush.interval.messages=10000\n##   log.flush.interval.ms=1000\n##   log.retention.hours=168\n##   log.retention.bytes=1073741824\n##   log.segment.bytes=1073741824\n##   log.retention.check.interval.ms=300000\n##   zookeeper.connect=ZOOKEEPER_SERVICE_NAME\n##   zookeeper.connection.timeout.ms=6000\n##   group.initial.rebalance.delay.ms=0\n##\nconfig: \"\"\n## @param existingConfigmap ConfigMap with Kafka Configuration\n## NOTE: This will override config AND any KAFKA_CFG_ environment variables.\n##\nexistingConfigmap: \"\"\n## @param log4j An optional log4j.properties file to overwrite the default of the Kafka brokers.\n## An optional log4j.properties file to overwrite the default of the Kafka brokers.\n## See an example log4j.properties at:\n## https://github.com/apache/kafka/blob/trunk/config/log4j.properties\n##\nlog4j: \"\"\n## @param existingLog4jConfigMap The name of an existing ConfigMap containing a log4j.properties file.\n## The name of an existing ConfigMap containing a log4j.properties file.\n## NOTE: this will override log4j.\n##\nexistingLog4jConfigMap: \"\"\n## @param heapOpts Kafka's Java Heap size\n##\nheapOpts: -Xmx1024m -Xms1024m\n## @param deleteTopicEnable Switch to enable topic deletion or not\n##\ndeleteTopicEnable: true\n## @param autoCreateTopicsEnable Switch to enable auto creation of topics. Enabling auto creation of topics not recommended for production or similar environments\n##\nautoCreateTopicsEnable: true\n## @param logFlushIntervalMessages The number of messages to accept before forcing a flush of data to disk\n##\nlogFlushIntervalMessages: _10000\n## @param logFlushIntervalMs The maximum amount of time a message can sit in a log before we force a flush\n##\nlogFlushIntervalMs: 1000\n## @param logRetentionBytes A size-based retention policy for logs\n##\nlogRetentionBytes: _1073741824\n## @param logRetentionCheckIntervalMs The interval at which log segments are checked to see if they can be deleted\n##\nlogRetentionCheckIntervalMs: 300000\n## @param logRetentionHours The minimum age of a log file to be eligible for deletion due to age\n##\nlogRetentionHours: 168\n## @param logSegmentBytes The maximum size of a log segment file. When this size is reached a new log segment will be created\n##\nlogSegmentBytes: _1073741824\n## @param logsDirs A comma separated list of directories under which to store log files\n##\nlogsDirs: /bitnami/kafka/data\n## @param maxMessageBytes The largest record batch size allowed by Kafka\n##\nmaxMessageBytes: _1000012\n## @param defaultReplicationFactor Default replication factors for automatically created topics\n##\ndefaultReplicationFactor: 1\n## @param offsetsTopicReplicationFactor The replication factor for the offsets topic\n##\noffsetsTopicReplicationFactor: 1\n## @param transactionStateLogReplicationFactor The replication factor for the transaction topic\n##\ntransactionStateLogReplicationFactor: 1\n## @param transactionStateLogMinIsr Overridden min.insync.replicas config for the transaction topic\n##\ntransactionStateLogMinIsr: 1\n## @param numIoThreads The number of threads doing disk I/O\n##\nnumIoThreads: 8\n## @param numNetworkThreads The number of threads handling network requests\n##\nnumNetworkThreads: 3\n## @param numPartitions The default number of log partitions per topic\n##\nnumPartitions: 1\n## @param numRecoveryThreadsPerDataDir The number of threads per data directory to be used for log recovery at startup and flushing at shutdown\n##\nnumRecoveryThreadsPerDataDir: 1\n## @param socketReceiveBufferBytes The receive buffer (SO_RCVBUF) used by the socket server\n##\nsocketReceiveBufferBytes: 102400\n## @param socketRequestMaxBytes The maximum size of a request that the socket server will accept (protection against OOM)\n##\nsocketRequestMaxBytes: _104857600\n## @param socketSendBufferBytes The send buffer (SO_SNDBUF) used by the socket server\n##\nsocketSendBufferBytes: 102400\n## @param zookeeperConnectionTimeoutMs Timeout in ms for connecting to Zookeeper\n##\nzookeeperConnectionTimeoutMs: 6000\n## @param authorizerClassName The Authorizer is configured by setting authorizer.class.name=kafka.security.authorizer.AclAuthorizer in server.properties.\n##\nauthorizerClassName: \"\"\n## @param allowEveryoneIfNoAclFound By default, if a resource has no associated ACLs, then no one is allowed to access that resource except super users.\n##\nallowEveryoneIfNoAclFound: true\n## @param superUsers You can add super users in server.properties\n##\nsuperUsers: User:admin\n## @param command Override kafka container command\n##\ncommand:\n  - /scripts/setup.sh\n## @param args Override kafka container arguments\n##\nargs: []\n## @param extraEnvVars Extra environment variables to add to kafka pods (see [below]({KEY}\n## ref: https://github.com/bitnami/bitnami-docker-kafka#configuration\n## Example:\n## extraEnvVars:\n##   - name: KAFKA_CFG_BACKGROUND_THREADS\n##     value: \"10\"\n##\nextraEnvVars: []\n## @param extraVolumes Extra volume(s) to add to Kafka statefulset\n## Examples:\n## extraVolumes:\n##   - name: kafka-jaas\n##     secret:\n##       secretName: kafka-jaas\nextraVolumes: []\n## @param extraVolumeMounts Extra volumeMount(s) to add to Kafka containers\n## extraVolumeMounts:\n##   - name: kafka-jaas\n##     mountPath: /bitnami/kafka/config/kafka_jaas.conf\n##     subPath: kafka_jaas.conf\nextraVolumeMounts: []\n## Authentication parameteres\n## https://github.com/bitnami/bitnami-docker-kafka#security\n##\nauth:\n  ## Authentication protocol for client and inter-broker communications\n  ## This table shows the security provided on each protocol:\n  ## | Method    | Authentication                | Encryption via TLS |\n  ## | plaintext | None                          | No                 |\n  ## | tls       | None                          | Yes                |\n  ## | mtls      | Yes (two-way authentication)  | Yes                |\n  ## | sasl      | Yes (via SASL)                | No                 |\n  ## | sasl_tls  | Yes (via SASL)                | Yes                |\n  ## @param auth.clientProtocol Authentication protocol for communications with clients. Allowed protocols: `plaintext`, `tls`, `mtls`, `sasl` and `sasl_tls`\n  ## @param auth.interBrokerProtocol Authentication protocol for inter-broker communications. Allowed protocols: `plaintext`, `tls`, `mtls`, `sasl` and `sasl_tls`\n  ##\n  clientProtocol: plaintext\n  interBrokerProtocol: plaintext\n  ## SASL configuration\n  ##\n  sasl:\n    ## @param auth.sasl.mechanisms SASL mechanisms when either `auth.interBrokerProtocol` or `auth.clientProtocol` are `sasl`. Allowed types: `plain`, `scram-sha-256`, `scram-sha-512`\n    ##\n    mechanisms: plain,scram-sha-256,scram-sha-512\n    ## @param auth.sasl.interBrokerMechanism SASL mechanism for inter broker communication.\n    ##\n    interBrokerMechanism: plain\n    ## JAAS configuration for SASL authentication.\n    ##\n    jaas:\n      ## @param auth.sasl.jaas.clientUsers Kafka client user list\n      ##\n      ## clientUsers:\n      ##   - user1\n      ##   - user2\n      ##\n      clientUsers:\n        - user\n      ## @param auth.sasl.jaas.clientPasswords Kafka client passwords. This is mandatory if more than one user is specified in clientUsers\n      ##\n      ## clientPasswords:\n      ##   - password1\n      ##   - password2\"\n      ##\n      clientPasswords: []\n      ## @param auth.sasl.jaas.interBrokerUser Kafka inter broker communication user for SASL authentication\n      ##\n      interBrokerUser: admin\n      ## @param auth.sasl.jaas.interBrokerPassword Kafka inter broker communication password for SASL authentication\n      ##\n      interBrokerPassword: \"\"\n      ## @param auth.sasl.jaas.zookeeperUser Kafka Zookeeper user for SASL authentication\n      ##\n      zookeeperUser: \"\"\n      ## @param auth.sasl.jaas.zookeeperPassword Kafka Zookeeper password for SASL authentication\n      ##\n      zookeeperPassword: \"\"\n      ## @param auth.sasl.jaas.existingSecret Name of the existing secret containing credentials for clientUsers, interBrokerUser and zookeeperUser\n      ## Create this secret running the command below where SECRET_NAME is the name of the secret you want to create:\n      ##       kubectl create secret generic SECRET_NAME --from-literal=client-passwords=CLIENT_PASSWORD1,CLIENT_PASSWORD2 --from-literal=inter-broker-password=INTER_BROKER_PASSWORD --from-literal=zookeeper-password=ZOOKEEPER_PASSWORD\n      ##\n      existingSecret: \"\"\n  ## @param auth.saslMechanisms DEPRECATED: use `auth.sasl.mechanisms` instead.\n  ##\n  saslMechanisms: plain,scram-sha-256,scram-sha-512\n  ## @param auth.saslInterBrokerMechanism DEPRECATED: use `auth.sasl.interBrokerMechanism` instead.\n  ##\n  saslInterBrokerMechanism: plain\n  ## @param auth.jaas [object] DEPRECATED: use `auth.sasl.jaas` instead.\n  ## @skip auth.jaas.clientUsers\n  ##\n  jaas:\n    clientUsers:\n      - user\n    clientPasswords: []\n    interBrokerUser: admin\n    interBrokerPassword: \"\"\n    zookeeperUser: \"\"\n    zookeeperPassword: \"\"\n    existingSecret: \"\"\n  ## TLS configuration\n  ##\n  tls:\n    ## @param auth.tls.type Format to use for TLS certificates. Allowed types: `jks` and `pem`\n    ##\n    type: jks\n    ## @param auth.tls.existingSecrets Array existing secrets containing the TLS certificates for the Kafka brokers\n    ## When using 'jks' format for certificates, each secret should contain a truststore and a keystore.\n    ## Create these secrets following the steps below:\n    ## 1) Generate your truststore and keystore files. Helpful script: https://raw.githubusercontent.com/confluentinc/confluent-platform-security-tools/master/kafka-generate-ssl.sh\n    ## 2) Rename your truststore to `kafka.truststore.jks`.\n    ## 3) Rename your keystores to `kafka-X.keystore.jks` where X is the ID of each Kafka broker.\n    ## 4) Run the command below one time per broker to create its associated secret (SECRET_NAME_X is the name of the secret you want to create):\n    ##       kubectl create secret generic SECRET_NAME_0 --from-file=kafka.truststore.jks=./kafka.truststore.jks --from-file=kafka.keystore.jks=./kafka-0.keystore.jks\n    ##       kubectl create secret generic SECRET_NAME_1 --from-file=kafka.truststore.jks=./kafka.truststore.jks --from-file=kafka.keystore.jks=./kafka-1.keystore.jks\n    ##       ...\n    ##\n    ## When using 'pem' format for certificates, each secret should contain a public CA certificate, a public certificate and one private key.\n    ## Create these secrets following the steps below:\n    ## 1) Create a certificate key and signing request per Kafka broker, and sign the signing request with your CA\n    ## 2) Rename your CA file to `kafka.ca.crt`.\n    ## 3) Rename your certificates to `kafka-X.tls.crt` where X is the ID of each Kafka broker.\n    ## 3) Rename your keys to `kafka-X.tls.key` where X is the ID of each Kafka broker.\n    ## 4) Run the command below one time per broker to create its associated secret (SECRET_NAME_X is the name of the secret you want to create):\n    ##       kubectl create secret generic SECRET_NAME_0 --from-file=ca.crt=./kafka.ca.crt --from-file=tls.crt=./kafka-0.tls.crt --from-file=tls.key=./kafka-0.tls.key\n    ##       kubectl create secret generic SECRET_NAME_1 --from-file=ca.crt=./kafka.ca.crt --from-file=tls.crt=./kafka-1.tls.crt --from-file=tls.key=./kafka-1.tls.key\n    ##       ...\n    ##\n    existingSecrets: []\n    ## @param auth.tls.existingSecret DEPRECATED: use `auth.tls.existingSecrets` instead.\n    ##\n    existingSecret: \"\"\n    ## @param auth.tls.autoGenerated Generate automatically self-signed TLS certificates for Kafka brokers. Currently only supported if `auth.tls.type` is `pem`\n    ## Note: ignored when using 'jks' format or `auth.tls.existingSecrets` is not empty\n    ##\n    autoGenerated: false\n    ## @param auth.tls.password Password to access the JKS files or PEM key when they are password-protected.\n    ##\n    password: \"\"\n    ## @param auth.tls.jksTruststoreSecret Name of the existing secret containing your truststore if truststore not existing or different from the ones in the `auth.tls.existingSecrets`\n    ## Note: ignored when using 'pem' format for certificates .\n    ##\n    jksTruststoreSecret: \"\"\n    ## @param auth.tls.jksKeystoreSAN The secret key from the `auth.tls.existingSecret` containing the keystore with a SAN certificate\n    ## The SAN certificate in it should be issued with Subject Alternative Names for all headless services:\n    ##  - kafka-0.kafka-headless.kafka.svc.cluster.local\n    ##  - kafka-1.kafka-headless.kafka.svc.cluster.local\n    ##  - kafka-2.kafka-headless.kafka.svc.cluster.local\n    ## Note: ignored when using 'pem' format for certificates.\n    ##\n    jksKeystoreSAN: \"\"\n    ## @param auth.tls.jksTruststore The secret key from the `auth.tls.existingSecret` or `auth.tls.jksTruststoreSecret` containing the truststore\n    ## Note: ignored when using 'pem' format for certificates.\n    ##\n    jksTruststore: \"\"\n    ## @param auth.tls.endpointIdentificationAlgorithm The endpoint identification algorithm to validate server hostname using server certificate\n    ## Disable server host name verification by setting it to an empty string.\n    ## ref: https://docs.confluent.io/current/kafka/authentication_ssl.html#optional-settings\n    ##\n    endpointIdentificationAlgorithm: https\n  ## @param auth.jksSecret DEPRECATED: use `auth.tls.existingSecrets` instead.\n  ##\n  jksSecret: \"\"\n  ## @param auth.jksTruststoreSecret DEPRECATED: use `auth.tls.jksTruststoreSecret` instead.\n  ##\n  jksTruststoreSecret: \"\"\n  ## @param auth.jksKeystoreSAN DEPRECATED: use `auth.tls.jksKeystoreSAN` instead.\n  ##\n  jksKeystoreSAN: \"\"\n  ## @param auth.jksTruststore DEPRECATED: use `auth.tls.jksTruststore` instead.\n  ##\n  jksTruststore: \"\"\n  ## @param auth.jksPassword DEPRECATED: use `auth.tls.password` instead.\n  ##\n  jksPassword: \"\"\n  ## @param auth.tlsEndpointIdentificationAlgorithm DEPRECATED: use `auth.tls.endpointIdentificationAlgorithm` instead.\n  ##\n  tlsEndpointIdentificationAlgorithm: https\n## @param listeners The address(es) the socket server listens on. Auto-calculated it's set to an empty array\n## When it's set to an empty array, the listeners will be configured\n## based on the authentication protocols (auth.clientProtocol and auth.interBrokerProtocol parameters)\n##\nlisteners: []\n## @param advertisedListeners The address(es) (hostname:port) the broker will advertise to producers and consumers. Auto-calculated it's set to an empty array\n## When it's set to an empty array, the advertised listeners will be configured\n## based on the authentication protocols (auth.clientProtocol and auth.interBrokerProtocol parameters)\n##\nadvertisedListeners: []\n## @param listenerSecurityProtocolMap The protocol-\u003elistener mapping. Auto-calculated it's set to nil\n## When it's nil, the listeners will be configured based on the authentication protocols (auth.clientProtocol and auth.interBrokerProtocol parameters)\n##\nlistenerSecurityProtocolMap: \"\"\n## @param allowPlaintextListener Allow to use the PLAINTEXT listener\n##\nallowPlaintextListener: true\n## @param interBrokerListenerName The listener that the brokers should communicate on\n##\ninterBrokerListenerName: INTERNAL\n\n## @section Statefulset parameters\n\n## @param replicaCount Number of Kafka nodes\n##\nreplicaCount: \"1\"\n## @param minBrokerId Minimal broker.id value, nodes increment their `broker.id` respectively\n## Brokers increment their ID starting at this minimal value.\n## E.g., with `minBrokerId=100` and 3 nodes, IDs will be 100, 101, 102 for brokers 0, 1, and 2, respectively.\n##\nminBrokerId: 0\n## @param updateStrategy Update strategy for the stateful set\n## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#updating-statefulsets\n##\nupdateStrategy: RollingUpdate\n## @param rollingUpdatePartition Partition update strategy\n## https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#partitions\n##\nrollingUpdatePartition: \"\"\n## @param hostAliases Add deployment host aliases\n## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n##\nhostAliases: []\n## @param podManagementPolicy StatefulSet controller supports relax its ordering guarantees while preserving its uniqueness and identity guarantees. There are two valid pod management policies: OrderedReady and Parallel\n## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy\n##\npodManagementPolicy: Parallel\n## @param schedulerName Name of the k8s scheduler (other than default)\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\nschedulerName: \"\"\n## @param podLabels Kafka pod labels\n## Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n##\npodLabels: {}\n## @param podAnnotations Kafka Pod annotations\n## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n##\npodAnnotations: {}\n## @param priorityClassName Name of the existing priority class to be used by kafka pods\n## Ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/\n##\npriorityClassName: \"\"\n## @param podAffinityPreset Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n##\npodAffinityPreset: \"\"\n## @param podAntiAffinityPreset Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n##\npodAntiAffinityPreset: soft\n## Node affinity preset\n## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n##\nnodeAffinityPreset:\n  ## @param nodeAffinityPreset.type Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n  ##\n  type: \"\"\n  ## @param nodeAffinityPreset.key Node label key to match Ignored if `affinity` is set.\n  ## E.g.\n  ## key: \"kubernetes.io/e2e-az-name\"\n  ##\n  key: \"\"\n  ## @param nodeAffinityPreset.values Node label values to match. Ignored if `affinity` is set.\n  ## E.g.\n  ## values:\n  ##   - e2e-az1\n  ##   - e2e-az2\n  ##\n  values: []\n## @param affinity Affinity for pod assignment\n## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n## Note: podAffinityPreset, podAntiAffinityPreset, and  nodeAffinityPreset will be ignored when it's set\n##\naffinity: {}\n## @param nodeSelector Node labels for pod assignment\n## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n##\nnodeSelector: {}\n## @param tolerations Tolerations for pod assignment\n## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n##\ntolerations: []\n## @param topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template\n## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods\n##\ntopologySpreadConstraints: {}\n## @param terminationGracePeriodSeconds Seconds the pod needs to gracefully terminate\n## ref: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#hook-handler-execution\n##\nterminationGracePeriodSeconds: \"\"\n## Kafka pods' Security Context\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n## @param podSecurityContext.enabled Enable security context for the pods\n## @param podSecurityContext.fsGroup Group ID for the filesystem used by the containers\n## @param podSecurityContext.runAsUser User ID for the service user running the pod\n##\npodSecurityContext:\n  enabled: true\n  fsGroup: 1001\n  runAsUser: 1001\n## @param containerSecurityContext Kafka containers' Security Context\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n## Example:\n##   containerSecurityContext:\n##     capabilities:\n##       drop: [\"NET_RAW\"]\n##     readOnlyRootFilesystem: true\n##\ncontainerSecurityContext: {}\n## Kafka containers' resource requests and limits\n## ref: http://kubernetes.io/docs/user-guide/compute-resources/\n## We usually recommend not to specify default resources and to leave this as a conscious\n## choice for the user. This also increases chances charts run on environments with little\n## resources, such as Minikube. If you do want to specify resources, uncomment the following\n## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n## @param resources.limits The resources limits for Kafka containers\n## @param resources.requests The requested resources for Kafka containers\n##\nresources:\n  ## Example:\n  ## limits:\n  ##    cpu: 250m\n  ##    memory: 1Gi\n  limits: {}\n  ## Examples:\n  ## requests:\n  ##    cpu: 250m\n  ##    memory: 256Mi\n  requests: {}\n## Kafka containers' liveness probe. Evaluated as a template.\n## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes\n## @param livenessProbe.enabled Enable livenessProbe\n## @param livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n## @param livenessProbe.periodSeconds Period seconds for livenessProbe\n## @param livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n## @param livenessProbe.failureThreshold Failure threshold for livenessProbe\n## @param livenessProbe.successThreshold Success threshold for livenessProbe\n##\nlivenessProbe:\n  enabled: true\n  initialDelaySeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 3\n  periodSeconds: 10\n  successThreshold: 1\n## Kafka containers' readiness probe. Evaluated as a template.\n## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes\n## @param readinessProbe.enabled Enable readinessProbe\n## @param readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n## @param readinessProbe.periodSeconds Period seconds for readinessProbe\n## @param readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n## @param readinessProbe.failureThreshold Failure threshold for readinessProbe\n## @param readinessProbe.successThreshold Success threshold for readinessProbe\n##\nreadinessProbe:\n  enabled: true\n  initialDelaySeconds: 5\n  failureThreshold: 6\n  timeoutSeconds: 5\n  periodSeconds: 10\n  successThreshold: 1\n## @param customLivenessProbe Custom Liveness probe configuration for Kafka\n##\ncustomLivenessProbe: {}\n## @param customReadinessProbe Custom Readiness probe configuration for Kafka\n##\ncustomReadinessProbe: {}\n## Pod Disruption Budget configuration\n## The PDB will only be created if replicaCount is greater than 1\n## ref: https://kubernetes.io/docs/concepts/workloads/pods/disruptions\n##\npdb:\n  ## @param pdb.create Enable/disable a Pod Disruption Budget creation\n  ##\n  create: false\n  ## @param pdb.minAvailable Minimum number/percentage of pods that should remain scheduled\n  ##\n  minAvailable: \"\"\n  ## @param pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable\n  ##\n  maxUnavailable: 1\n## @param sidecars Attach additional sidecar containers to the Kafka pod\n## Example:\n## sidecars:\n##   - name: your-image-name\n##     image: your-image\n##     imagePullPolicy: Always\n##     ports:\n##       - name: portname\n##         containerPort: 1234\n##\nsidecars: []\n## @param initContainers Add extra init containers\n##\ninitContainers: []\n\n## @section Exposure parameters\n\n## Service parameters\n##\nservice:\n  ## @param service.type Kubernetes Service type\n  ##\n  type: ClusterIP\n  ## @param service.port Kafka port for client connections\n  ##\n  port: 9092\n  ## @param service.internalPort Kafka port for inter-broker connections\n  ##\n  internalPort: 9093\n  ## @param service.externalPort Kafka port for external connections\n  ##\n  externalPort: 9094\n  ## @param service.nodePorts [object] Specify the nodePort value for the LoadBalancer and NodePort service types.\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n  ##\n  nodePorts:\n    client: \"\"\n    external: \"\"\n  ## @param service.loadBalancerIP loadBalancerIP for Kafka Service\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer\n  ##\n  loadBalancerIP: \"\"\n  ## @param service.loadBalancerSourceRanges Address(es) that are allowed when service is LoadBalancer\n  ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n  ## Example:\n  ## loadBalancerSourceRanges:\n  ## - 10.10.10.0/24\n  ##\n  loadBalancerSourceRanges: []\n  ## @param service.annotations Service annotations\n  ##\n  annotations: {}\n## External Access to Kafka brokers configuration\n##\nexternalAccess:\n  ## @param externalAccess.enabled Enable Kubernetes external cluster access to Kafka brokers\n  ##\n  enabled: true\n  ## External IPs auto-discovery configuration\n  ## An init container is used to auto-detect LB IPs or node ports by querying the K8s API\n  ## Note: RBAC might be required\n  ##\n  autoDiscovery:\n    ## @param externalAccess.autoDiscovery.enabled Enable using an init container to auto-detect external IPs/ports by querying the K8s API\n    ##\n    enabled: true\n    ## Bitnami Kubectl image\n    ## ref: https://hub.docker.com/r/bitnami/kubectl/tags/\n    ## @param externalAccess.autoDiscovery.image.registry Init container auto-discovery image registry\n    ## @param externalAccess.autoDiscovery.image.repository Init container auto-discovery image repository\n    ## @param externalAccess.autoDiscovery.image.tag Init container auto-discovery image tag (immutable tags are recommended)\n    ## @param externalAccess.autoDiscovery.image.pullPolicy Init container auto-discovery image pull policy\n    ## @param externalAccess.autoDiscovery.image.pullSecrets Init container auto-discovery image pull secrets\n    ##\n    image:\n      registry: docker.io\n      repository: bitnami/kubectl\n      tag: 1.19.15-debian-10-r39\n      ## Specify a imagePullPolicy\n      ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n      ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n      ##\n      pullPolicy: IfNotPresent\n      ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)\n      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n      ## Example:\n      ## pullSecrets:\n      ##   - myRegistryKeySecretName\n      ##\n      pullSecrets: []\n    ## Init Container resource requests and limits\n    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/\n    ## We usually recommend not to specify default resources and to leave this as a conscious\n    ## choice for the user. This also increases chances charts run on environments with little\n    ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n    ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n    ## @param externalAccess.autoDiscovery.resources.limits Init container auto-discovery resource limits\n    ## @param externalAccess.autoDiscovery.resources.requests Init container auto-discovery resource requests\n    ##\n    resources:\n      ## Example:\n      ## limits:\n      ##    cpu: 100m\n      ##    memory: 128Mi\n      limits: {}\n      ## Examples:\n      ## requests:\n      ##    cpu: 100m\n      ##    memory: 128Mi\n      requests: {}\n  ## Parameters to configure K8s service(s) used to externally access Kafka brokers\n  ## A new service per broker will be created\n  ##\n  service:\n    ## @param externalAccess.service.type Kubernetes Service type for external access. It can be NodePort or LoadBalancer\n    ##\n    type: \"NodePort\"\n    ## @param externalAccess.service.port Kafka port used for external access when service type is LoadBalancer\n    ##\n    port: \"9092\"\n    ## @param externalAccess.service.loadBalancerIPs Array of load balancer IPs for each Kafka broker. Length must be the same as replicaCount\n    ## Example:\n    ## loadBalancerIPs:\n    ##   - X.X.X.X\n    ##   - Y.Y.Y.Y\n    ##\n    loadBalancerIPs: []\n    ## @param externalAccess.service.loadBalancerSourceRanges Address(es) that are allowed when service is LoadBalancer\n    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n    ## Example:\n    ## loadBalancerSourceRanges:\n    ## - 10.10.10.0/24\n    ##\n    loadBalancerSourceRanges: []\n    ## @param externalAccess.service.nodePorts Array of node ports used for each Kafka broker. Length must be the same as replicaCount\n    ## Example:\n    ## nodePorts:\n    ##   - 30001\n    ##   - 30002\n    ##\n    nodePorts: []\n    ## @param externalAccess.service.useHostIPs Use service host IPs to configure Kafka external listener when service type is NodePort\n    ##\n    useHostIPs: false\n    ## @param externalAccess.service.domain Domain or external ip used to configure Kafka external listener when service type is NodePort\n    ## If not specified, the container will try to get the kubernetes node external IP\n    ##\n    domain: \"\"\n    ## @param externalAccess.service.annotations Service annotations for external access\n    ##\n    annotations: {}\n    ## @param externalAccess.service.usePodIPs using the MY_POD_IP address for external access.\n    ##\n    usePodIPs: false\n\n## @section Persistence parameters\n\n## Persistence parameters\n##\npersistence:\n  ## @param persistence.enabled Enable Kafka data persistence using PVC, note that Zookeeper persistence is unaffected\n  ##\n  enabled: true\n  ## @param persistence.existingClaim Provide an existing `PersistentVolumeClaim`, the value is evaluated as a template\n  ## If defined, PVC must be created manually before volume will be bound\n  ## The value is evaluated as a template\n  ##\n  existingClaim: \"\"\n  ## @param persistence.storageClass PVC Storage Class for Kafka data volume\n  ## If defined, storageClassName: \u003cstorageClass\u003e\n  ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n  ## If undefined (the default) or set to null, no storageClassName spec is\n  ## set, choosing the default provisioner.\n  ##\n  storageClass: \"\"\n  ## @param persistence.accessModes PV Access Mode\n  ##\n  accessModes:\n    - ReadWriteOnce\n  ## @param persistence.size PVC Storage Request for Kafka data volume\n  ##\n  size: \"2Gi\"\n  ## @param persistence.annotations Annotations for the PVC\n  ##\n  annotations: {}\n  ## @param persistence.selector Selector to match an existing Persistent Volume for Kafka's data PVC. If set, the PVC can't have a PV dynamically provisioned for it\n  ## selector:\n  ##   matchLabels:\n  ##     app: my-app\n  selector: {}\n  ## @param persistence.mountPath Mount path of the Kafka data volume\n  ##\n  mountPath: /bitnami/kafka\n## Log Persistence parameters\n##\nlogPersistence:\n  ## @param logPersistence.enabled Enable Kafka logs persistence using PVC, note that Zookeeper persistence is unaffected\n  ##\n  enabled: false\n  ## @param logPersistence.existingClaim A manually managed Persistent Volume and Claim\n  ## If defined, PVC must be created manually before volume will be bound\n  ## The value is evaluated as a template\n  ##\n  existingClaim: \"\"\n  ## @param logPersistence.existingLogClaim PV Storage Class\n  ## If defined, storageClassName: \u003cstorageClass\u003e\n  ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n  ## If undefined (the default) or set to null, no storageClassName spec is\n  ## set, choosing the default provisioner.\n  existingLogClaim: \"\"\n  ## @param logPersistence.accessModes PV Access Mode\n  ##\n  accessModes:\n    - ReadWriteOnce\n  ## @param logPersistence.size PVC Storage Request for Kafka logs volume\n  ##\n  size: 8Gi\n  ## @param logPersistence.annotations Annotations for the PVC\n  ##\n  annotations: {}\n  ## @param logPersistence.selector Selector to match an existing Persistent Volume for Kafka's log data PVC. If set, the PVC can't have a PV dynamically provisioned for it\n  ## selector:\n  ##   matchLabels:\n  ##     app: my-app\n  selector: {}\n  ## @param logPersistence.mountPath Mount path of the Kafka logs volume\n  ##\n  mountPath: /opt/bitnami/kafka/logs\n\n## @section RBAC parameters\n\n## Kafka pods ServiceAccount\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n##\nserviceAccount:\n  ## @param serviceAccount.create Enable creation of ServiceAccount for Kafka pods\n  ##\n  create: true\n  ## @param serviceAccount.name The name of the service account to use. If not set and `create` is `true`, a name is generated\n  ## If not set and create is true, a name is generated using the kafka.serviceAccountName template\n  ##\n  name: \"\"\n  ## @param serviceAccount.automountServiceAccountToken Allows auto mount of ServiceAccountToken on the serviceAccount created\n  ## Can be set to false if pods using this serviceAccount do not need to use K8s API\n  ##\n  automountServiceAccountToken: true\n## Role Based Access\n## ref: https://kubernetes.io/docs/admin/authorization/rbac/\n##\nrbac:\n  ## @param rbac.create Whether to create \u0026 use RBAC resources or not\n  ## binding Kafka ServiceAccount to a role\n  ## that allows Kafka pods querying the K8s API\n  ##\n  create: true\n\n## @section Volume Permissions parameters\n\n## Init Container parameters\n## Change the owner and group of the persistent volume(s) mountpoint(s) to 'runAsUser:fsGroup' on each component\n## values from the securityContext section of the component\n##\nvolumePermissions:\n  ## @param volumePermissions.enabled Enable init container that changes the owner and group of the persistent volume(s) mountpoint to `runAsUser:fsGroup`\n  ##\n  enabled: false\n  ## The security context for the volumePermissions init container\n  ## @param volumePermissions.securityContext.runAsUser User ID for the container\n  ##\n  securityContext:\n    runAsUser: 0\n  ## @param volumePermissions.image.registry Init container volume-permissions image registry\n  ## @param volumePermissions.image.repository Init container volume-permissions image name\n  ## @param volumePermissions.image.tag Init container volume-permissions image tag\n  ## @param volumePermissions.image.pullPolicy Init container volume-permissions image pull policy\n  ## @param volumePermissions.image.pullSecrets Specify docker-registry secret names as an array\n  ##\n  image:\n    registry: docker.io\n    repository: bitnami/bitnami-shell\n    tag: 10-debian-10-r234\n    ## Specify a imagePullPolicy\n    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n    ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n    ##\n    pullPolicy: IfNotPresent\n    ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    ## Example:\n    ## pullSecrets:\n    ##   - myRegistryKeySecretName\n    ##\n    pullSecrets: []\n  ## Init Container resource requests and limits\n  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param volumePermissions.resources.limits Init container volume-permissions resource  limits\n  ## @param volumePermissions.resources.requests Init container volume-permissions resource  requests\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##    cpu: 100m\n    ##    memory: 128Mi\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##    cpu: 100m\n    ##    memory: 128Mi\n    requests: {}\n\n## @section Metrics parameters\n\n## Prometheus Exporters / Metrics\n##\nmetrics:\n  ## Prometheus Kafka Exporter: exposes complimentary metrics to JMX Exporter\n  ##\n  kafka:\n    ## @param metrics.kafka.enabled Whether or not to create a standalone Kafka exporter to expose Kafka metrics\n    ##\n    enabled: false\n    ## Bitnami Kafka exporter image\n    ## ref: https://hub.docker.com/r/bitnami/kafka-exporter/tags/\n    ## @param metrics.kafka.image.registry Kafka exporter image registry\n    ## @param metrics.kafka.image.repository Kafka exporter image repository\n    ## @param metrics.kafka.image.tag Kafka exporter image tag (immutable tags are recommended)\n    ## @param metrics.kafka.image.pullPolicy Kafka exporter image pull policy\n    ## @param metrics.kafka.image.pullSecrets Specify docker-registry secret names as an array\n    ##\n    image:\n      registry: docker.io\n      repository: bitnami/kafka-exporter\n      tag: 1.4.2-debian-10-r41\n      ## Specify a imagePullPolicy\n      ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n      ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n      ##\n      pullPolicy: IfNotPresent\n      ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)\n      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n      ## Example:\n      ## pullSecrets:\n      ##   - myRegistryKeySecretName\n      ##\n      pullSecrets: []\n    ## Kafka exporter pods ServiceAccount\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    ##\n    serviceAccount:\n      ## @param metrics.kafka.serviceAccount.create Enable creation of ServiceAccount for Kafka exporter pods\n      ##\n      create: true\n      ## @param metrics.kafka.serviceAccount.name The name of the service account to use. If not set and `create` is `true`, a name is generated\n      ## If not set and create is true, a name is generated using the kafka.metrics.kafka.serviceAccountName template\n      ##\n      name: \"\"\n      ## @param metrics.kafka.serviceAccount.automountServiceAccountToken Allows auto mount of ServiceAccountToken on the serviceAccount created\n      ## Can be set to false if pods using this serviceAccount do not need to use K8s API\n      ##\n      automountServiceAccountToken: true\n    ## @param metrics.kafka.schedulerName Name of the k8s scheduler (other than default) for Kafka Exporter\n    ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n    ##\n    schedulerName: \"\"\n    ## @param metrics.kafka.extraFlags Extra flags to be passed to Kafka exporter\n    ## Example:\n    ## extraFlags:\n    ##   tls.insecure-skip-tls-verify: \"\"\n    ##   web.telemetry-path: \"/metrics\"\n    ##\n    extraFlags: {}\n    ## @param metrics.kafka.certificatesSecret Name of the existing secret containing the optional certificate and key files\n    ## for Kafka Exporter client authentication\n    ##\n    certificatesSecret: \"\"\n    ## @param metrics.kafka.tlsCert The secret key from the certificatesSecret if 'client-cert' key different from the default (cert-file)\n    ##\n    tlsCert: cert-file\n    ## @param metrics.kafka.tlsKey The secret key from the certificatesSecret if 'client-key' key different from the default (key-file)\n    ##\n    tlsKey: key-file\n    ## @param metrics.kafka.tlsCaSecret Name of the existing secret containing the optional ca certificate for Kafka Exporter client authentication\n    ##\n    tlsCaSecret: \"\"\n    ## @param metrics.kafka.tlsCaCert The secret key from the certificatesSecret or tlsCaSecret if 'ca-cert' key different from the default (ca-file)\n    ##\n    tlsCaCert: ca-file\n    ## @param metrics.kafka.podLabels Kafka exporter pod labels\n    ## Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n    ##\n    podLabels: {}\n    ## @param metrics.kafka.podAnnotations Kafka exporter pod annotations\n    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n    ##\n    podAnnotations: {}\n    ## Prometheus Kafka Exporter' resource requests and limits\n    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/\n    ## We usually recommend not to specify default resources and to leave this as a conscious\n    ## choice for the user. This also increases chances charts run on environments with little\n    ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n    ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n    ## @param metrics.kafka.resources.limits Kafka Exporter container resource limits\n    ## @param metrics.kafka.resources.requests Kafka Exporter container resource requests\n    ##\n    resources:\n      ## Example:\n      ## limits:\n      ##    cpu: 100m\n      ##    memory: 128Mi\n      limits: {}\n      ## Examples:\n      ## requests:\n      ##    cpu: 100m\n      ##    memory: 128Mi\n      requests: {}\n    ## @param metrics.kafka.affinity Affinity for Kafka Exporter pod assignment\n    ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n    ## Note: podAffinityPreset, podAntiAffinityPreset, and  nodeAffinityPreset will be ignored when it's set\n    ##\n    affinity: {}\n    ## @param metrics.kafka.nodeSelector Node labels for Kafka Exporter pod assignment\n    ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n    ##\n    nodeSelector: {}\n    ## @param metrics.kafka.tolerations Tolerations for Kafka Exporter pod assignment\n    ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n    ##\n    tolerations: []\n    ## @param metrics.kafka.initContainers Add init containers to the Kafka exporter pods\n    ## Example:\n    ## initContainers:\n    ##   - name: your-image-name\n    ##     image: your-image\n    ##     imagePullPolicy: Always\n    ##     ports:\n    ##       - name: portname\n    ##         containerPort: 1234\n    ##\n    initContainers: []\n    ## Service configuration\n    ##\n    service:\n      ## @param metrics.kafka.service.type Kubernetes service type (`ClusterIP`, `NodePort` or `LoadBalancer`) for Kafka Exporter\n      ##\n      type: ClusterIP\n      ## @param metrics.kafka.service.port Kafka Exporter Prometheus port\n      ##\n      port: 9308\n      ## @param metrics.kafka.service.nodePort Kubernetes HTTP node port\n      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n      ##\n      nodePort: \"\"\n      ## @param metrics.kafka.service.loadBalancerIP loadBalancerIP if service type is `LoadBalancer`\n      ## Set the LoadBalancer service type to internal only\n      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer\n      ##\n      loadBalancerIP: \"\"\n      ## @param metrics.kafka.service.loadBalancerSourceRanges Load Balancer sources\n      ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n      ## Example:\n      ## loadBalancerSourceRanges:\n      ## - 10.10.10.0/24\n      ##\n      loadBalancerSourceRanges: []\n      ## @param metrics.kafka.service.clusterIP Static clusterIP or None for headless services\n      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#choosing-your-own-ip-address\n      ##\n      clusterIP: \"\"\n      ## @param metrics.kafka.service.annotations [object] Annotations for the Kafka Exporter Prometheus metrics service\n      ##\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"9308\"\n        prometheus.io/path: \"/metrics\"\n  ## Prometheus JMX Exporter: exposes the majority of Kafkas metrics\n  ##\n  jmx:\n    ## @param metrics.jmx.enabled Whether or not to expose JMX metrics to Prometheus\n    ##\n    enabled: false\n    ## Bitnami JMX exporter image\n    ## ref: https://hub.docker.com/r/bitnami/jmx-exporter/tags/\n    ## @param metrics.jmx.image.registry JMX exporter image registry\n    ## @param metrics.jmx.image.repository JMX exporter image repository\n    ## @param metrics.jmx.image.tag JMX exporter image tag (immutable tags are recommended)\n    ## @param metrics.jmx.image.pullPolicy JMX exporter image pull policy\n    ## @param metrics.jmx.image.pullSecrets Specify docker-registry secret names as an array\n    ##\n    image:\n      registry: docker.io\n      repository: bitnami/jmx-exporter\n      tag: 0.16.1-debian-10-r103\n      ## Specify a imagePullPolicy\n      ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n      ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n      ##\n      pullPolicy: IfNotPresent\n      ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)\n      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n      ## Example:\n      ## pullSecrets:\n      ##   - myRegistryKeySecretName\n      ##\n      pullSecrets: []\n    ## Prometheus JMX Exporter' resource requests and limits\n    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/\n    ## We usually recommend not to specify default resources and to leave this as a conscious\n    ## choice for the user. This also increases chances charts run on environments with little\n    ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n    ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n    ## @param metrics.jmx.resources.limits JMX Exporter container resource limits\n    ## @param metrics.jmx.resources.requests JMX Exporter container resource requests\n    ##\n    resources:\n      ## Example:\n      ## limits:\n      ##    cpu: 100m\n      ##    memory: 128Mi\n      limits: {}\n      ## Examples:\n      ## requests:\n      ##    cpu: 100m\n      ##    memory: 128Mi\n      requests: {}\n    ## Service configuration\n    ##\n    service:\n      ## @param metrics.jmx.service.type Kubernetes service type (`ClusterIP`, `NodePort` or `LoadBalancer`) for JMX Exporter\n      ##\n      type: ClusterIP\n      ## @param metrics.jmx.service.port JMX Exporter Prometheus port\n      ##\n      port: 5556\n      ## @param metrics.jmx.service.nodePort Kubernetes HTTP node port\n      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n      ##\n      nodePort: \"\"\n      ## @param metrics.jmx.service.loadBalancerIP loadBalancerIP if service type is `LoadBalancer`\n      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer\n      ##\n      loadBalancerIP: \"\"\n      ## @param metrics.jmx.service.loadBalancerSourceRanges Load Balancer sources\n      ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n      ## Example:\n      ## loadBalancerSourceRanges:\n      ## - 10.10.10.0/24\n      ##\n      loadBalancerSourceRanges: []\n      ## @param metrics.jmx.service.clusterIP Static clusterIP or None for headless services\n      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#choosing-your-own-ip-address\n      ##\n      clusterIP: \"\"\n      ## @param metrics.jmx.service.annotations [object] Annotations for the JMX Exporter Prometheus metrics service\n      ##\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"5556\"\n        prometheus.io/path: \"/\"\n    ## @param metrics.jmx.whitelistObjectNames Allows setting which JMX objects you want to expose to via JMX stats to JMX Exporter\n    ## Only whitelisted values will be exposed via JMX Exporter. They must also be exposed via Rules. To expose all metrics\n    ## (warning its crazy excessive and they aren't formatted in a prometheus style) (1) `whitelistObjectNames: []`\n    ## (2) commented out above `overrideConfig`.\n    ##\n    whitelistObjectNames:\n      - kafka.controller:*\n      - kafka.server:*\n      - java.lang:*\n      - kafka.network:*\n      - kafka.log:*\n    ## @param metrics.jmx.config [string] Configuration file for JMX exporter\n    ## Specify content for jmx-kafka-prometheus.yml. Evaluated as a template\n    ##\n    ## Credits to the incubator/kafka chart for the JMX configuration.\n    ## https://github.com/helm/charts/tree/master/incubator/kafka\n    ##\n    config: |-\n      jmxUrl: service:jmx:rmi:///jndi/rmi://127.0.0.1:5555/jmxrmi\n      lowercaseOutputName: true\n      lowercaseOutputLabelNames: true\n      ssl: false\n      whitelistObjectNames: [\"\\\"kafka.controller:*\\\", \\\"kafka.server:*\\\", \\\"java.lang:*\\\", \\\"kafka.network:*\\\", \\\"kafka.log:*\\\"\"]\n    ## @param metrics.jmx.existingConfigmap Name of existing ConfigMap with JMX exporter configuration\n    ## NOTE: This will override metrics.jmx.config\n    ##\n    existingConfigmap: \"\"\n  ## Prometheus Operator ServiceMonitor configuration\n  ##\n  serviceMonitor:\n    ## @param metrics.serviceMonitor.enabled if `true`, creates a Prometheus Operator ServiceMonitor (requires `metrics.kafka.enabled` or `metrics.jmx.enabled` to be `true`)\n    ##\n    enabled: false\n    ## @param metrics.serviceMonitor.namespace Namespace in which Prometheus is running\n    ##\n    namespace: \"\"\n    ## @param metrics.serviceMonitor.interval Interval at which metrics should be scraped\n    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint\n    ##\n    interval: \"\"\n    ## @param metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended\n    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint\n    ##\n    scrapeTimeout: \"\"\n    ## @param metrics.serviceMonitor.selector ServiceMonitor selector labels\n    ## ref: https://github.com/bitnami/charts/tree/master/bitnami/prometheus-operator#prometheus-configuration\n    ## e.g:\n    ## selector:\n    ##   prometheus: my-prometheus\n    ##\n    selector: {}\n    ## @param metrics.serviceMonitor.relabelings Relabel configuration for the metrics\n    ##\n    relabelings: []\n    ## @param metrics.serviceMonitor.metricRelabelings MetricRelabelConfigs to apply to samples before ingestion\n    ##\n    metricRelabelings: []\n\n## @section Kafka provisioning parameters\n\n## Kafka provisioning\n##\nprovisioning:\n  ## @param provisioning.enabled Enable kafka provisioning Job\n  ##\n  enabled: false\n  ## @param provisioning.numPartitions Default number of partitions for topics when unspecified.\n  numPartitions: 1\n  ## @param provisioning.replicationFactor Default replication factor for topics when unspecified.\n  replicationFactor: 1\n  ## @param provisioning.schedulerName Name of the k8s scheduler (other than default) for kafka provisioning\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  schedulerName: \"\"\n  ## @param provisioning.podAnnotations Provisioning Pod annotations.\n  ##\n  podAnnotations: {}\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param provisioning.resources.limits The resources limits for the container\n  ## @param provisioning.resources.requests The requested resources for the container\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##    cpu: 250m\n    ##    memory: 1Gi\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##    cpu: 250m\n    ##    memory: 256Mi\n    requests: {}\n  ## @param provisioning.command Override provisioning container command\n  ##\n  command: []\n  ## @param provisioning.args Override provisioning container arguments\n  ##\n  args: []\n  ## @param provisioning.topics Kafka provisioning topics\n  ## - name: topic-name\n  ##   partitions: 1\n  ##   replicationFactor: 1\n  ##   ## https://kafka.apache.org/documentation/#topicconfigs\n  ##   config:\n  ##     max.message.bytes: 64000\n  ##     flush.messages: 1\n  ##\n  topics: []\n\n## @section Zookeeper chart parameters\n\n## Zookeeper chart configuration\n## https://github.com/bitnami/charts/blob/master/bitnami/zookeeper/values.yaml\n##\nzookeeper:\n  ## @param zookeeper.enabled Switch to enable or disable the Zookeeper helm chart\n  ##\n  enabled: \"true\"\n  auth:\n    ## @param zookeeper.auth.enabled Enable Zookeeper auth\n    ##\n    enabled: false\n    ## @param zookeeper.auth.clientUser User that will use Zookeeper clients to auth\n    ##\n    clientUser: \"\"\n    ## @param zookeeper.auth.clientPassword Password that will use Zookeeper clients to auth\n    ##\n    clientPassword: \"\"\n    ## @param zookeeper.auth.serverUsers Comma, semicolon or whitespace separated list of user to be created. Specify them as a string, for example: \"user1,user2,admin\"\n    ##\n    serverUsers: \"\"\n    ## @param zookeeper.auth.serverPasswords Comma, semicolon or whitespace separated list of passwords to assign to users when created. Specify them as a string, for example: \"pass4user1, pass4user2, pass4admin\"\n    ##\n    serverPasswords: \"\"\n  heapSize: \"256\"\n  replicaCount: \"1\"\n\n## This value is only used when zookeeper.enabled is set to false\n##\nexternalZookeeper:\n  ## @param externalZookeeper.servers Server or list of external Zookeeper servers to use\n  ##\n  servers: []\n\n#################### Zookeeper Variables ######################\n\n# zookeeper:\n#   image:\n#     registry: docker.io\n#     repository: bitnami/zookeeper\n#     tag: 3.6-debian-10\n#     pullPolicy: Always\n\n#   heapSize: 256\n#   replicaCount: 3\n\n#   resources:\n#     requests:\n#       memory: 256Mi\n#       cpu: 512m\n\n#   tickTime: 2000\n#   initLimit: 10\n#   syncLimit: 5\n#   preAllocSize: 65536\n#   snapCount: 100000\n#   maxClientCnxns: 60\n#   fourlwCommandsWhitelist: srvr, mntr, ruok\n#   listenOnAllIPs: false\n#   allowAnonymousLogin: true\n#   autopurge:\n#     snapRetainCount: 3\n#     purgeInterval: 0\n#   maxSessionTimeout: 40000\n\n#   allowAnonymousLogin: true\n\n#   minServerId: 1\n\n#   # securityContext:\n#   #   enabled: true\n#   #   fsGroup: 1001\n#   #   runAsUser: 1001\n\n#   livenessProbe:\n#     enabled: true\n#     initialDelaySeconds: 30\n#     periodSeconds: 10\n#     timeoutSeconds: 5\n#     failureThreshold: 6\n#     successThreshold: 1\n#     probeCommandTimeout: 2\n\n#   readinessProbe:\n#     enabled: true\n#     initialDelaySeconds: 5\n#     periodSeconds: 10\n#     timeoutSeconds: 5\n#     failureThreshold: 6\n#     successThreshold: 1\n#     probeCommandTimeout: 2\n\n#   service:\n#     type: ClusterIP\n#     # loadBalancerIP: \"\"\n#     port: 2181\n#     followerPort: 2888\n#     electionPort: 3888\n#     nodePorts:\n#       client: \"\"\n#       clientTls: \"\"\n#     publishNotReadyAddresses: true\n#     tlsClientPort: 3181\n#     disableBaseClientPort: false\n#     annotations: {}\n#     headless:\n#       annotations: {}\n\n\n"
            ],
            "verify": false,
            "version": "14.0.0",
            "wait": true,
            "wait_for_jobs": true
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "kind_cluster.one-click"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "postgres",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "https://charts.bitnami.com/bitnami/postgresql-11.9.1.tgz",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "postgresql",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "14.5.0",
                "chart": "postgresql",
                "name": "postgresql",
                "namespace": "postgres",
                "revision": 1,
                "values": "{\"auth\":{\"database\":\"druid_raw\",\"enablePostgresUser\":true,\"existingSecret\":\"\",\"password\":\"druid\",\"postgresPassword\":\"postgres\",\"username\":\"druid\"},\"primary\":{\"initdb\":{\"password\":\"postgres\",\"scripts\":{\"00_create_superset_db.sql\":\"CREATE DATABASE superset;\\n\",\"01_create_superset_user.sql\":\"CREATE USER superset WITH ENCRYPTED PASSWORD 'superset$123';\\nGRANT ALL PRIVILEGES ON DATABASE superset TO superset;\"},\"user\":\"postgres\"},\"persistence\":{\"enabled\":true,\"mountPath\":\"/bitnami/postgresql\",\"size\":\"1Gi\",\"storageClass\":\"standard\"}}}",
                "version": "11.9.1"
              }
            ],
            "name": "postgresql",
            "namespace": "postgres",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": null,
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 600,
            "values": [
              "auth:\n  enablePostgresUser: true\n  postgresPassword: postgres\n  database: \"druid_raw\"\n  username: \"druid\"\n  password: \"druid\"\n  existingSecret: \"\"\n  \nprimary: \n  persistence: \n    size: 1Gi\n    enabled: true\n    mountPath: /bitnami/postgresql\n    storageClass: \"standard\"\n\n  initdb:\n    user: \"postgres\"\n    password: \"postgres\"\n    scripts:\n      00_create_superset_db.sql: |\n        CREATE DATABASE superset;\n      01_create_superset_user.sql: |\n        CREATE USER superset WITH ENCRYPTED PASSWORD 'superset$123';\n        GRANT ALL PRIVILEGES ON DATABASE superset TO superset;"
            ],
            "verify": false,
            "version": "11.9.1",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "kind_cluster.one-click"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kind_cluster",
      "name": "one-click",
      "provider": "provider[\"registry.terraform.io/kyma-incubator/kind\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "client_certificate": "-----BEGIN CERTIFICATE-----\nMIIDITCCAgmgAwIBAgIIOff7Pnbjal0wDQYJKoZIhvcNAQELBQAwFTETMBEGA1UE\nAxMKa3ViZXJuZXRlczAeFw0yMzAxMDUwNjE3MTRaFw0yNDAxMDUwNjE3MTVaMDQx\nFzAVBgNVBAoTDnN5c3RlbTptYXN0ZXJzMRkwFwYDVQQDExBrdWJlcm5ldGVzLWFk\nbWluMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA3Bzr1xvDbJT2SgD5\nZBZtCoV5Q6a8/i8hrXm9jhl7XwjWBnH5TBoWqztIYL2bPVTWcaF5bvvt6GQAYTGg\nU8ezbY8fUaZiNlWRlcYPAEZRTpTK8hzYfB7u/YYijF+ggiN62pyVsE7eDwo4W5+j\nObQCEetc144LCY0cETx/YhWlkswZv7ryefwmX6PA7DqhSXkAywX3J5dz7I+51HX/\nITmXFcEtJTZ4gyQskqujO1xrBesWQFAB49bGlT/pgDzamiEhe2Juoau4/GP/9bNG\n+EX3gpQL1JAFIHtAAcLbklonR9H58PCvFzNoLUce4cjMGK14Gsd04u0VzOVT22LZ\neyvVvwIDAQABo1YwVDAOBgNVHQ8BAf8EBAMCBaAwEwYDVR0lBAwwCgYIKwYBBQUH\nAwIwDAYDVR0TAQH/BAIwADAfBgNVHSMEGDAWgBQRJwkUxaTMHBOkHXBdJbTZyLco\nkDANBgkqhkiG9w0BAQsFAAOCAQEAdRHxVJohL1iWI0kevMPIGgeXY+HNLto3j2jv\nSmTKlkItZzakAYLebpDskH8NSJo3FEwc/LYVxXfUHAZK/kMwoQ+Va87i1KtjXBtz\nQwcM9Aury98bdkXFO8dYzMcKYo9xOYf3zp97cD/X6Imp9k07ZXARTk0ODjDV+hwm\nGawKRGTvYS9YybT1fPRAU0HZMauWVJrw+NQPCkBbaZ0VbrARJvX3Ol26eP5NONFp\n1+577fmHBiCkIopYu9X4wZUWXOdlvNb0gZ0QaaE0Q7kbsCW4tQhJ0aLtpXgKaxuj\nYeAJ9diknhbXQI9LMKTTyxNnkwsgF0zCeYWNs6LSVSqJyPcJ3A==\n-----END CERTIFICATE-----\n",
            "client_key": "-----BEGIN RSA PRIVATE KEY-----\nMIIEowIBAAKCAQEA3Bzr1xvDbJT2SgD5ZBZtCoV5Q6a8/i8hrXm9jhl7XwjWBnH5\nTBoWqztIYL2bPVTWcaF5bvvt6GQAYTGgU8ezbY8fUaZiNlWRlcYPAEZRTpTK8hzY\nfB7u/YYijF+ggiN62pyVsE7eDwo4W5+jObQCEetc144LCY0cETx/YhWlkswZv7ry\nefwmX6PA7DqhSXkAywX3J5dz7I+51HX/ITmXFcEtJTZ4gyQskqujO1xrBesWQFAB\n49bGlT/pgDzamiEhe2Juoau4/GP/9bNG+EX3gpQL1JAFIHtAAcLbklonR9H58PCv\nFzNoLUce4cjMGK14Gsd04u0VzOVT22LZeyvVvwIDAQABAoIBAEsTLjmLRad2U17A\nYE+L+psZFVhGubV0u+bgXA/ojxTF/cHrA926FDtJGBGu+hD8K7xMGBALq4SU/zAn\nbgjFV2Sp6UO/HUZs/x/3ksxEL50+0M2tmwUSw+8C3ivEvglFMrT3rXKaI9E7aieO\nFm0rAX29Kkh3MTqLv6P9X3FD8tpTUxHoAANpN4iGpBIpJrBRR/o0Idlr1Ve5qb6m\n6rhUckjllZbJXSYg+kt8LU7RKK2Q0hwVk3L+ke+/NTF0LKlg7YVTEtRXUfzcl64Y\nUJ7b6ZJIZtaA8Zrt8rQuD9fvsweAQ9KA4TkMxGgUufgxamyddkh8Q1O05ziudPEr\nwRMGbhkCgYEA69oIi7I/SmjlpEGX7n1+kQk9eBmLLglV8ATUdr4lgSNmk42kaMfO\n/U4mpEv18U9kxZMPlfyb9uvgcCXCDHkNrzS3ZL6iiE47HoFGjf7rQycrG1cXWlL3\n7qTTiRlqw+DUtkOAdfM1xe68OIFq3ABt/cmubjhIxfwDzGzldpBMxV0CgYEA7uqw\nfWT3xaVKK6MqeIJWoGncPW/D4kFJL8r5QWO3yDyjEQP7Pi2JYXh2jnWP6q9CDMZ/\nLPb0NOkSFukm6d9dmmcvy6AyYaNabgztdunXZUBweU3R0CDV89nfvCJV9UtxQ5mY\nLEqkteYR2Ge5/44tPCcVVyfihew7xLUQb1uGWcsCgYEAo36+w9BpzXRQFQCfiOUX\n8wTbxsC2WdCA8WT3v+TqbM4Ukp7y5Ov2EmS1ptk9ge2OpuPePxQhLhevuy6BiVH1\naYp6w2zfkOviUbA+L7sSbbfeSxKhjqzLUHSUa4riFy1pZ3v9tkZF9ZMciXM1l5L4\nrKC9uYxs7kpYe8LVgs5fWcUCgYA+2jzt8BcCxvYZPsaYh2l0sATBoNp+dkBjs1kZ\na7tYkSMxAcQh2mbu3nsKBUGEMvEEXV/tm1YpaTtaDaIwGpQMX6MCRbWbXBcZJot+\nIgyJVYeBUgilYU4H5cRnQP0uF9fHOev/ku977ve436jd4zBhR8Lkd9iu9LPQjvWw\n5foVOwKBgAfrIfJ7SbKWAmTG9msOPahbIs3EQErvFve35f7OiZ3xOkJqT1cNnezd\nhfZYgLQXWW4+CSusQAZgBqSUnhLkJ4ouR47Yi9tGVv5EPak6Z6XAp5A/ju8u8QGg\nvpz4hzahYqdmgSg1qGjqlg9czHDhpnOZuEIzcBIjiHbAyu2CHydg\n-----END RSA PRIVATE KEY-----\n",
            "cluster_ca_certificate": "-----BEGIN CERTIFICATE-----\nMIIC5zCCAc+gAwIBAgIBADANBgkqhkiG9w0BAQsFADAVMRMwEQYDVQQDEwprdWJl\ncm5ldGVzMB4XDTIzMDEwNTA2MTcxNFoXDTMzMDEwMjA2MTcxNFowFTETMBEGA1UE\nAxMKa3ViZXJuZXRlczCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBANTf\n8CXNvm81RATcx/tM96V6u6uYGoACOYQU4SBw1HNkwi9h2EGNwfMSWAWFoO4HnLig\n2CuZHygYY+Ob41DR/ie4XIA4V4UNv1CNCQTA3dWV1oxLes7B7UXFTW6VCeHtInVO\n7zu9oTu2lWzhMJAeWLJLdHs+MW6hSfsFY/UoyfrSo+Z1pgNBrME5eQqtsDgd6nkb\nP6Qb02grwG6jaNo2HIYFhjarMxFp/YClBBL1+WUwu9H5SAqC+Aj63KM9bNPnvodx\ndjmqdYD2POHJLDYRojvsrvEzsVwktOFIoH+2DcRB93ISzxMJ5BnBCLLF4+AJu8Vf\n5Xx6a6DRS/BTsF05WSsCAwEAAaNCMEAwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB\n/wQFMAMBAf8wHQYDVR0OBBYEFBEnCRTFpMwcE6QdcF0ltNnItyiQMA0GCSqGSIb3\nDQEBCwUAA4IBAQA+Cf5mcqFsrHRIC94ltY/NWOl/Pdzfwy9tSuDgJqFaGF1IW+e/\nyBm+j65GPo8Qn/m1/dq+Ela4Qd3evmyY60QP90+GFkcY47q9zUkeQSVJwvX9dhMb\nQXuTf5VN4utAGaYPhvThUEM/X5u8jcBd9WJ/fIRNWerGLAkyqr8YY6asNDzuZ2tN\nU0iRFLMv89+D/YpOk/sopt1JP1hBLZsyjVzL5ebc/WjcLy0aNdHgLUSTrHhZeshr\nBFlkgs36q53w0xfNzsChT6X7+yI4UTH809xVv4nFwoysDcLMhVAJtN9PYd0qiXI5\nRq2ra4m89e4th/O2v1UaIYdTelYvcKL50gjb\n-----END CERTIFICATE-----\n",
            "endpoint": "https://127.0.0.1:57468",
            "id": "one-click-",
            "kind_config": [
              {
                "api_version": "kind.x-k8s.io/v1alpha4",
                "containerd_config_patches": null,
                "kind": "Cluster",
                "networking": [],
                "node": [
                  {
                    "extra_mounts": [],
                    "extra_port_mappings": [
                      {
                        "container_port": 80,
                        "host_port": 80,
                        "listen_address": "",
                        "protocol": ""
                      },
                      {
                        "container_port": 443,
                        "host_port": 443,
                        "listen_address": "",
                        "protocol": ""
                      }
                    ],
                    "image": "",
                    "kubeadm_config_patches": [
                      "kind: InitConfiguration\nnodeRegistration:\n  kubeletExtraArgs:\n    node-labels: \"ingress-ready=true\"\n"
                    ],
                    "role": "control-plane"
                  },
                  {
                    "extra_mounts": [],
                    "extra_port_mappings": [],
                    "image": "",
                    "kubeadm_config_patches": [
                      "kind: InitConfiguration\nnodeRegistration:\n  kubeletExtraArgs:\n    node-labels: \"worker-node=true\"\n"
                    ],
                    "role": "worker"
                  },
                  {
                    "extra_mounts": [],
                    "extra_port_mappings": [],
                    "image": "",
                    "kubeadm_config_patches": [
                      "kind: InitConfiguration\nnodeRegistration:\n  kubeletExtraArgs:\n    node-labels: \"worker-node=true\"\n"
                    ],
                    "role": "worker"
                  },
                  {
                    "extra_mounts": [],
                    "extra_port_mappings": [],
                    "image": "",
                    "kubeadm_config_patches": [
                      "kind: InitConfiguration\nnodeRegistration:\n  kubeletExtraArgs:\n    node-labels: \"worker-node=true\"\n"
                    ],
                    "role": "worker"
                  }
                ]
              }
            ],
            "kubeconfig": "apiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM1ekNDQWMrZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJek1ERXdOVEEyTVRjeE5Gb1hEVE16TURFd01qQTJNVGN4TkZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTlRmCjhDWE52bTgxUkFUY3gvdE05NlY2dTZ1WUdvQUNPWVFVNFNCdzFITmt3aTloMkVHTndmTVNXQVdGb080SG5MaWcKMkN1Wkh5Z1lZK09iNDFEUi9pZTRYSUE0VjRVTnYxQ05DUVRBM2RXVjFveExlczdCN1VYRlRXNlZDZUh0SW5WTwo3enU5b1R1MmxXemhNSkFlV0xKTGRIcytNVzZoU2ZzRlkvVW95ZnJTbytaMXBnTkJyTUU1ZVFxdHNEZ2Q2bmtiClA2UWIwMmdyd0c2amFObzJISVlGaGphck14RnAvWUNsQkJMMStXVXd1OUg1U0FxQytBajYzS005Yk5QbnZvZHgKZGptcWRZRDJQT0hKTERZUm9qdnNydkV6c1Z3a3RPRklvSCsyRGNSQjkzSVN6eE1KNUJuQkNMTEY0K0FKdThWZgo1WHg2YTZEUlMvQlRzRjA1V1NzQ0F3RUFBYU5DTUVBd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZCRW5DUlRGcE13Y0U2UWRjRjBsdE5uSXR5aVFNQTBHQ1NxR1NJYjMKRFFFQkN3VUFBNElCQVFBK0NmNW1jcUZzckhSSUM5NGx0WS9OV09sL1BkemZ3eTl0U3VEZ0pxRmFHRjFJVytlLwp5Qm0rajY1R1BvOFFuL20xL2RxK0VsYTRRZDNldm15WTYwUVA5MCtHRmtjWTQ3cTl6VWtlUVNWSnd2WDlkaE1iClFYdVRmNVZONHV0QUdhWVBodlRoVUVNL1g1dThqY0JkOVdKL2ZJUk5XZXJHTEFreXFyOFlZNmFzTkR6dVoydE4KVTBpUkZMTXY4OStEL1lwT2svc29wdDFKUDFoQkxac3lqVnpMNWViYy9XamNMeTBhTmRIZ0xVU1RySGhaZXNocgpCRmxrZ3MzNnE1M3cweGZOenNDaFQ2WDcreUk0VVRIODA5eFZ2NG5Gd295c0RjTE1oVkFKdE45UFlkMHFpWEk1ClJxMnJhNG04OWU0dGgvTzJ2MVVhSVlkVGVsWXZjS0w1MGdqYgotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\n    server: https://127.0.0.1:57468\n  name: kind-one-click\ncontexts:\n- context:\n    cluster: kind-one-click\n    user: kind-one-click\n  name: kind-one-click\ncurrent-context: kind-one-click\nkind: Config\npreferences: {}\nusers:\n- name: kind-one-click\n  user:\n    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURJVENDQWdtZ0F3SUJBZ0lJT2ZmN1BuYmphbDB3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TXpBeE1EVXdOakUzTVRSYUZ3MHlOREF4TURVd05qRTNNVFZhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQTNCenIxeHZEYkpUMlNnRDUKWkJadENvVjVRNmE4L2k4aHJYbTlqaGw3WHdqV0JuSDVUQm9XcXp0SVlMMmJQVlRXY2FGNWJ2dnQ2R1FBWVRHZwpVOGV6Ylk4ZlVhWmlObFdSbGNZUEFFWlJUcFRLOGh6WWZCN3UvWVlpakYrZ2dpTjYycHlWc0U3ZUR3bzRXNStqCk9iUUNFZXRjMTQ0TENZMGNFVHgvWWhXbGtzd1p2N3J5ZWZ3bVg2UEE3RHFoU1hrQXl3WDNKNWR6N0krNTFIWC8KSVRtWEZjRXRKVFo0Z3lRc2txdWpPMXhyQmVzV1FGQUI0OWJHbFQvcGdEemFtaUVoZTJKdW9hdTQvR1AvOWJORworRVgzZ3BRTDFKQUZJSHRBQWNMYmtsb25SOUg1OFBDdkZ6Tm9MVWNlNGNqTUdLMTRHc2QwNHUwVnpPVlQyMkxaCmV5dlZ2d0lEQVFBQm8xWXdWREFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0RBWURWUjBUQVFIL0JBSXdBREFmQmdOVkhTTUVHREFXZ0JRUkp3a1V4YVRNSEJPa0hYQmRKYlRaeUxjbwprREFOQmdrcWhraUc5dzBCQVFzRkFBT0NBUUVBZFJIeFZKb2hMMWlXSTBrZXZNUElHZ2VYWStITkx0bzNqMmp2ClNtVEtsa0l0Wnpha0FZTGVicERza0g4TlNKbzNGRXdjL0xZVnhYZlVIQVpLL2tNd29RK1ZhODdpMUt0alhCdHoKUXdjTTlBdXJ5OThiZGtYRk84ZFl6TWNLWW85eE9ZZjN6cDk3Y0QvWDZJbXA5azA3WlhBUlRrME9EakRWK2h3bQpHYXdLUkdUdllTOVl5YlQxZlBSQVUwSFpNYXVXVkpydytOUVBDa0JiYVowVmJyQVJKdlgzT2wyNmVQNU5PTkZwCjErNTc3Zm1IQmlDa0lvcFl1OVg0d1pVV1hPZGx2TmIwZ1owUWFhRTBRN2tic0NXNHRRaEowYUx0cFhnS2F4dWoKWWVBSjlkaWtuaGJYUUk5TE1LVFR5eE5ua3dzZ0YwekNlWVdOczZMU1ZTcUp5UGNKM0E9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\n    client-key-data: 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\n",
            "kubeconfig_path": "./kube/kube_local.yaml",
            "name": "one-click",
            "node_image": null,
            "timeouts": null,
            "wait_for_ready": true
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjozMDAwMDAwMDAwMDAsImRlbGV0ZSI6MzAwMDAwMDAwMDAwLCJ1cGRhdGUiOjMwMDAwMDAwMDAwMH19"
        }
      ]
    }
  ],
  "check_results": null
}
